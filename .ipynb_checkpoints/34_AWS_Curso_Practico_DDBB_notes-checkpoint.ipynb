{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a11671",
   "metadata": {},
   "source": [
    "## <a name=\"index\"></a> Indice\n",
    "\n",
    "[Características de Relational Database Service (RDS)](#mark_01)\n",
    "\n",
    "[Desplegando nuestra primer base de datos](#mark_02)\n",
    "\n",
    "[Conexión gráfica a nuestra base de datos](#mark_03)\n",
    "\n",
    "[Conexión por consola a nuestra base de datos](#mark_04)\n",
    "\n",
    "[Estrategias de backup](#mark_05)\n",
    "\n",
    "[Demo - Restauración de un back-up automático en RDS.](#mark_06)\n",
    "\n",
    "[Estrategias de performance en RDS](#mark_07)\n",
    "\n",
    "[Despliegues Multi AZ](#mark_08)\n",
    "\n",
    "[Estrategias de migración a RDS](#mark_09)\n",
    "\n",
    "[Migraciones homogéneas y heterogéneas](#mark_10)\n",
    "\n",
    "[Casos de uso de RDS](#mark_11)\n",
    "\n",
    "[Introducción a Aurora](#mark_12)\n",
    "\n",
    "[Características de Aurora](#mark_13)\n",
    "\n",
    "[Casos de uso Aurora](#mark_14)\n",
    "\n",
    "[Aurora Serverless](#mark_15)\n",
    "\n",
    "<a name=\"index_01\"></a>\n",
    "\n",
    "[Casos de uso de Aurora](#mark_16)\n",
    "\n",
    "[Características de DynamoDB](#mark_17)\n",
    "\n",
    "[Consistencia en DynamoDB](#mark_18)\n",
    "\n",
    "[Creando nuestra primer tabla en DynamoDB](#mark_19)\n",
    "\n",
    "[Casos de uso en DynamoDB](#mark_20)\n",
    "\n",
    "[Índices y particiones en DynamoDB](#mark_21)\n",
    "\n",
    "[Operaciones Scan en DynamoDB](#mark_22)\n",
    "\n",
    "[Operaciones Query en DynamoDB](#mark_23)\n",
    "\n",
    "[Demo de operaciones Scan y Query en DynamoDB](#mark_24)\n",
    "\n",
    "[¿Qué es Local Seconday Index?](#mark_25)\n",
    "\n",
    "[Características Streams y Replicación en DynamoDB](#mark_26)\n",
    "\n",
    "[Casos de uso Streams y Replicación en DynamoDB](#mark_27)\n",
    "\n",
    "[DAX: DynamoDB Accelerator](#mark_28)\n",
    "\n",
    "[Conclusiones](#mark_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7da680",
   "metadata": {},
   "source": [
    "## <a name=\"mark_01\"></a>Características de Relational Database Service (RDS)\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "En AWS tenemos compatibilidad de 6 motores de ddbb.\n",
    "\n",
    "![](img_01.png)\n",
    "\n",
    "### Características del servicio:\n",
    "\n",
    "![](img_02.png)\n",
    "\n",
    "### Back-up automáticos:\n",
    "\n",
    "_ Podemos guardar hasta 35 días de back-up historico, con lo cual podríamos devolvernos al día 28 a las 12hs, XXmin, y XXseg. Por defecto este tiempo está seteado en 7 días.\n",
    "\n",
    "Luego de los 35 días de back-up automático de una RDS, los snapshots de la instancia de base de datos se eliminarán automáticamente. Esto significa que luego de 35 días, los datos de eso snapshots no estarán disponibles para su recuperación.\n",
    "\n",
    "Si necesita conservar los datos de la base de datos durante más de 35 días, puede utilizar la opción de retención prolongada. La retención prolongada permite conservar los snapshots de la instancia de base de datos durante un período de tiempo personalizado. El período de retención prolongado mínimo es de 30 días.\n",
    "\n",
    "También puede utilizar la opción de copiar los snapshots de la instancia de base de datos a un bucket de Amazon S3. Esto le permitirá conservar los snapshots de la instancia de base de datos durante el tiempo que desee.\n",
    "\n",
    "Aquí hay una tabla que resume las opciones disponibles para conservar los snapshots de la instancia de base de datos:\n",
    "\n",
    "| Opción | Período de retención | Descripción |\n",
    "|---|---|---|\n",
    "| Back-up automático | 35 días | Los snapshots se eliminan automáticamente después de 35 días. |\n",
    "| Retención prolongada | Hasta 365 días | Los snapshots se conservan durante un período de tiempo personalizado. |\n",
    "| Copia a un bucket de S3 | Sin límite | Los snapshots se conservan durante el tiempo que desee. |\n",
    "\n",
    "La opción más adecuada para usted dependerá de sus necesidades específicas. Si necesita conservar los datos de la base de datos durante un período de tiempo breve, el back-up automático es una buena opción. Si necesita conservar los datos de la base de datos durante un período de tiempo más prolongado, la retención prolongada o la copia a un bucket de S3 son mejores opciones.\n",
    "\n",
    "### Back-up manuales:\n",
    "\n",
    "_ Creados en cualquier momento desde la base de datos.\n",
    "\n",
    "_ Al eliminar una BD por defecto se crea un snapshot (puedes cambiar está opción si no lo deseas).\n",
    "\n",
    "![](img_03.png)\n",
    "\n",
    "### Storage (Sistema de Almacenamiento):\n",
    "\n",
    "Vamos a poder seleccionar 2 tipos de sistemas de almacenamiento:\n",
    "\n",
    "    - General Purpose (SSD): Para aquellas bases de datos con una carga de lectura y escritura \"muy constante\", si bien puede soportar picos, el storage no está diseñado para que esto sea el común denominador, en las operaciones de la ddbb. La cantidad de IOPS por defecto ya viene establecida con una relación fija.\n",
    "    \n",
    "    - Provisioned (SSD): Alto consumo de disco, altas operaciones de lectura y escritura. Uso intesivo de E/S (entrada y salida). Puedes seleccionar la cantidad de IOPS\n",
    "    \n",
    "Diferencia entre General Purpose y Provisiones --> El rendimiento, la cantidad de IOPS, y el pricing (Provisioned más costoso).\n",
    "\n",
    "### Seguridad:\n",
    "\n",
    "Podemos verlo desde diferentes perspectivas. \n",
    "\n",
    "Al nivel del cifrado de la información que está en nuestra db, podemos habilitar la encriptación de la data que está en la db con el servicio de KMS en Key Management Service (desde la consola), con lo cual nosotros podemos crear una llave de encriptación, especificar las personas o roles que van a poder usarla y administrarla, cuando creemos la db podemos habilitar la encriptación de nuestra db, esta es solo una de las medidas de seguridad, porque a nivel de seguridad también podemos hacer despliegues de la db dentro de la VPC (dentro de nuestra red), y a nivel de red podemos especificar, los grupos de seguridad especificando tráfico origen y por que protocolo va a venir, o podemos especificar reglas a nivel de sub-red utilizando NACL (Network Access Control List) para controlar tráfico a nivel de sub-red\n",
    "\n",
    "### Actualizaciones:\n",
    "\n",
    "RDS es un servicio completamente administrado, la carga operativa se va a reducir porque AWS realiza muchas cargas de administración de la db, una de ellas es encargarse de la actualización del motor, lo que podemos especificar es el tiempo y/o las ventanas de tiempo en las cuales se puede hacer estas actualizaciones.\n",
    "\n",
    "![](img_04.png)\n",
    "\n",
    "### IAM:\n",
    "\n",
    "Podríamos configurar nuestra db para que tenga integración con AWS, la parte de IAM los usuarios, roles, y políticas. \n",
    "\n",
    "    - Esta integración se hace por tokens para hacer la conexión a la db.\n",
    "    \n",
    "    - Lo máximo que puede estar soportando la integración con IAM es de 10 a 20 conexiones por segundo de los usuarios. Con lo cual esto es recomendable solo para escenarios de prueba o donde la concurrencia hacia la db no sea elevada.\n",
    "    \n",
    "### Monitoreo:\n",
    "\n",
    "Enhanced Monitoring --> Monitoreo a tiempo real (el pricing aumenta), hay ciertas opciones dentro de RDS que no van a funcionar si estamos trabajando con instancias muy pequeñas, ejemplo en \"small\" no se puede habilitar este monitoreo.\n",
    "\n",
    "### Pricing:\n",
    "\n",
    "Depende basicamente del almacenamiento y el tamaño de la instancia, monitoreo y otras configuraciones adisionales como despliegues en diferentes regiones, replicas de lectura, etc.\n",
    "\n",
    "![](img_05.png)\n",
    "\n",
    "### Oracle:\n",
    "\n",
    "Al momento de crear una db Oracle, el sistema nos entregará un endpoint de conexión a esa db.\n",
    "\n",
    "Los límites de Oracle:\n",
    "\n",
    "    - 1 Base de Datos por Instancia (En SQL Server podemos tener hasta 30 DDBB por instancia).\n",
    "    \n",
    "    - BYOL (Bring Your Own License) Incluida\n",
    "    \n",
    "    - Multi AZ (Multi Zona)\n",
    "    \n",
    "### Postgres:\n",
    "\n",
    "    - Base de Datos ilimitada por Instancia.\n",
    "    \n",
    "    - SW Adiciones (Pluging adicionales)\n",
    "    \n",
    "    - Multi AZ (Multi Zona)\n",
    "    \n",
    "### MariaDB:\n",
    "\n",
    "    - Base de Datos ilimitada por Instancia.    \n",
    "    \n",
    "    - Optimización para Queries.\n",
    "    \n",
    "    - Multi AZ (Multi Zona)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3084c",
   "metadata": {},
   "source": [
    "## <a name=\"mark_02\"></a>Desplegando nuestra primer base de datos\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_06.png)\n",
    "\n",
    "![](img_07.png)\n",
    "\n",
    "### Select Engine\n",
    "\n",
    "![](img_08.png)\n",
    "\n",
    "### En la parte inferior vemos las características (MySQL).\n",
    "\n",
    "![](img_09.png)\n",
    "\n",
    "_ Soporta db hasta 32 TB\n",
    "\n",
    "_ Las instacias pueden crecer hasta estar conformadas por 32 CPUs y 244 GB de Memoria.\n",
    "\n",
    "_ Soporta back-up automaticos y restauración en el tiempo.\n",
    "\n",
    "_ Soporata Corss-region read replicas ( lectura de replicas en distintas regiones)\n",
    "\n",
    "### Características para MariaDB\n",
    "\n",
    "![](img_10.png)\n",
    "\n",
    "### Características para Postgres\n",
    "\n",
    "![](img_11.png)\n",
    "\n",
    "### Características para Oracle:\n",
    "\n",
    "Dependerá del licenciamiento y las funcionalidades que necesitemos.\n",
    "\n",
    "![](img_12.png)\n",
    "\n",
    "### Características para SQL Server:\n",
    "\n",
    "Dependerá del licenciamiento y las funcionalidades que necesitemos.\n",
    "\n",
    "![](img_13.png)\n",
    "\n",
    "### Opción de MySQL (Dev/Test).\n",
    "\n",
    "Como se observa en la siguiente imagen nos recomienda \"Aurora\" ya que es la base de datos desarrollada por Amazon (puede ser más robusta en cuanto a performance y cuestiones de disponibilidad).\n",
    "\n",
    "Si la vamos a usar en producción Production - MySQL, se habilitan otras funcionalidades.\n",
    "\n",
    "Para MySQL podemos hacer uso de la capa gratuita que nos da AWS cuando creamos nuestra cuenta de Amazon.\n",
    "\n",
    "![](img_14.png)\n",
    "\n",
    "![](img_15.png)\n",
    "\n",
    "![](img_16.png)\n",
    "\n",
    "La seleccion de db.t2.micro habilita unas pocas opciones de configuración.\n",
    "\n",
    "![](img_17.png)\n",
    "\n",
    "![](img_18.png)\n",
    "\n",
    "### Opción de Production - MySQL.\n",
    "\n",
    "Contamos con las mismas opciones de versionado, por defecto aparace la instancia db.t2.micro y las replicas multizona activas.\n",
    "\n",
    "![](img_19.png)\n",
    "\n",
    "Debido a la replicación, el costo se incrementa.\n",
    "\n",
    "![](img_21.png)\n",
    "\n",
    "### Importante!!!\n",
    "\n",
    "En la parte de storage type, por defecto figura General Purpose, pero podemos cambiarlo a Provisioned y especificar la cantiad de IOPS.\n",
    "\n",
    "![](img_20.png)\n",
    "\n",
    "### Seguimos con los settings y \"Next\":\n",
    "\n",
    "![](img_22.png)\n",
    "\n",
    "### Configurar seteos avanzados:\n",
    "\n",
    "Podemos desplegar nuestra db dentro de una VPC.\n",
    "\n",
    "![](img_23.png)\n",
    "\n",
    "Si bien la recomendación es \"Public accessibility\" --> \"NO\", para este ejemplo dejaremos en \"YES\" y veremos como quedan las politicas de seguridad.\n",
    "\n",
    "![](img_24.png)\n",
    "\n",
    "![](img_25.png)\n",
    "\n",
    "![](img_26.png)\n",
    "\n",
    "IAM deshabilitado (recomendado para ambientes productivos)\n",
    "\n",
    "![](img_27.png)\n",
    "\n",
    "![](img_28.png)\n",
    "\n",
    "![](img_29.png)\n",
    "\n",
    "![](img_30.png)\n",
    "\n",
    "![](img_31.png)\n",
    "\n",
    "![](img_32.png)\n",
    "\n",
    "Si por algún motivo al momento de realizar el mantenimiento la db no está disponible, automaticamente el servicio apunta a la db de réplica para no interrumpir el servicio.\n",
    "\n",
    "Finalmente --> \"Create database\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1188c1",
   "metadata": {},
   "source": [
    "## <a name=\"mark_03\"></a>Conexión gráfica a nuestra base de datos\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Con nuestra db ya creada...\n",
    "\n",
    "![](img_33.png)\n",
    "\n",
    "Ingresamos a la db con un click sobre el nombre de la db.\n",
    "\n",
    "![](img_34.png)\n",
    "\n",
    "También podremos ver el monitoreo que se realiza sobre la db con los siguientes gráficos.\n",
    "\n",
    "_ CPU Utilization (Percent)\n",
    "\n",
    "_ DB Connections (Count)\n",
    "\n",
    "_ Free Storage Space (MB)\n",
    "\n",
    "_ Free Memory (MB)\n",
    "\n",
    "_ Write IOPS (Count/Second)\n",
    "\n",
    "_ Read IOPS (Count/Second)\n",
    "\n",
    "Detalles y características de la db.\n",
    "\n",
    "![](img_36.png)\n",
    "\n",
    "### Conexión a la db:\n",
    "\n",
    "Lo primero que vamos a mirar es **\"Security Group\"**, como vemos en la siguiente imagen tenemos el Security Group creado por defecto, con los inbound and outbound.\n",
    "\n",
    "### Recordar:\n",
    "\n",
    "`*************************************************************************************************************************`\n",
    "\n",
    "En el contexto de los grupos de seguridad en AWS, inbound y outbound se refieren al tráfico que entra y sale de un recurso protegido por un grupo de seguridad.\n",
    "\n",
    "**Inbound** se refiere al tráfico que entra en un recurso protegido por un grupo de seguridad. Las reglas de entrada definen qué tráfico se permite que entre en un recurso.\n",
    "\n",
    "**Outbound** se refiere al tráfico que sale de un recurso protegido por un grupo de seguridad. Las reglas de salida definen qué tráfico se permite que salga de un recurso.\n",
    "\n",
    "Las reglas de entrada y salida se definen mediante el protocolo, el puerto y la dirección IP o el rango de direcciones IP. Por ejemplo, una regla de entrada podría permitir que el tráfico HTTP entrante desde cualquier dirección IP se conecte a un servidor web. Una regla de salida podría permitir que el tráfico TCP saliente desde un servidor web se conecte a cualquier dirección IP en el puerto 80.\n",
    "\n",
    "Los grupos de seguridad se utilizan para controlar el acceso a los recursos protegidos en AWS. Las reglas de entrada y salida permiten que solo el tráfico autorizado acceda a los recursos.\n",
    "\n",
    "Aquí hay algunos ejemplos de cómo se pueden utilizar las reglas de entrada y salida:\n",
    "\n",
    "* **Para permitir que los usuarios de la web accedan a una aplicación web:** Se podría crear una regla de entrada que permita el tráfico HTTP entrante desde cualquier dirección IP.\n",
    "* **Para permitir que los clientes se conecten a una base de datos:** Se podría crear una regla de entrada que permita el tráfico TCP entrante desde direcciones IP específicas.\n",
    "* **Para permitir que los servidores se comuniquen entre sí:** Se podría crear una regla de salida que permita el tráfico TCP saliente desde un servidor a otro servidor.\n",
    "\n",
    "Es importante configurar las reglas de entrada y salida de los grupos de seguridad con cuidado para garantizar que solo el tráfico autorizado tenga acceso a los recursos.\n",
    "`*************************************************************************************************************************`\n",
    "\n",
    "![](img_37.png)\n",
    "\n",
    "Si engresamos al grupo de seguridad (click en los numeritos azules) --> Inbound, veremos la regla creada por defecto para conectarse con un IP especifica (identificando automaticamente nuestra IP de origen, con /32 para que solamente yo pueda ingreasar a la db).\n",
    "\n",
    "![](img_38.png)\n",
    "\n",
    "Luego podremos ver el endpoint y puerto necesario para la conexión con nuestro administrador de DDBB (para este ejemplo MySQL Workbench).\n",
    "\n",
    "![](img_35.png)\n",
    "\n",
    "En MySQL Workbech hacemos click en agregar una nueva conexión.\n",
    "\n",
    "![](img_39.png)\n",
    "\n",
    "Username: user name de la db creada\n",
    "\n",
    "password: password de la db creada\n",
    "\n",
    "![](img_40.png)\n",
    "\n",
    "![](img_41.png)\n",
    "\n",
    "![](img_42.png)\n",
    "\n",
    "![](img_43.png)\n",
    "\n",
    "Como se observa en la siguiente imagen con ese endpoint puedo tener multiples ddbb, tener en cuenta que si vamos a crear 100 ddbb la instancia micro, no soportará tantas ddbb. Debe haber una relación entre la cantidad de ddbb y la instancia, para entender esa relación/rendimiento debemos utilizar el monitoreo. Si deseamos que cada ddbb tenga un usuario completamente independiente, entonces debemos realizar la configuración a nivel de la CLI, para especificar el nuevo usuario y sobre que bases de datos tiene permiso y que tipo de permisos tiene.\n",
    "\n",
    "![](img_44.png)\n",
    "\n",
    "Podemos crear tablas.\n",
    "\n",
    "![](img_45.png)\n",
    "\n",
    "![](img_46.png)\n",
    "\n",
    "Características de la tabla.\n",
    "\n",
    "![](img_47.png)\n",
    "\n",
    "![](img_48.png)\n",
    "\n",
    "![](img_49.png)\n",
    "\n",
    "![](img_50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f13e55",
   "metadata": {},
   "source": [
    "## <a name=\"mark_04\"></a>Conexión por consola a nuestra base de datos\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Creamos una instancia EC2 con imagen de Linux, y un volumen Root de 8 GB, en el paso 6 configuramos un nuevo grupo de seguridad para permitir que nos podamos conectar desde nuestra IP por el puerto 22, siendo que después deberíamos garantizar que la instancia EC2 se vea con la db a travez del puerto 3306 \n",
    "\n",
    "![](img_51.png)\n",
    "\n",
    "Creamos la nueva llave, la descargamos y lanzamos la instancia.\n",
    "\n",
    "![](img_52.png)\n",
    "\n",
    "Siguiente paso, permitir la conexión de EC2 <--> DDBB, para eso modificamos los grupos de seguridad\n",
    "\n",
    "Grupo de seguridad EC2:\n",
    "\n",
    "![](img_53.png)\n",
    "\n",
    "![](img_54.png)\n",
    "\n",
    "![](img_55.png)\n",
    "\n",
    "Por el puerto 3306 permitir el tráfico que viene del grupo de seguridad de la instancia EC2.\n",
    "\n",
    "![](img_56.png)\n",
    "\n",
    "Ahora al revés tomamos el Group ID del grupo de seguridad de la db.\n",
    "\n",
    "![](img_57.png)\n",
    "\n",
    "Vamos a la instancia EC2 y agregamos una nueva regla.\n",
    "\n",
    "![](img_58.png)\n",
    "\n",
    "![](img_59.png)\n",
    "\n",
    "### Nos conectamos con EC2 a la db.\n",
    "\n",
    "![](img_60.png)\n",
    "\n",
    "![](img_61.png)\n",
    "\n",
    "Verificamos que los paquetes de mysql esten instalados.\n",
    "\n",
    "![](img_62.png)\n",
    "\n",
    "Ahora realizamos la cadena de conexión \"mysql -h endpoint -P 3306 -u user -p\", el último -p es para el password de la db.\n",
    "\n",
    "![](img_63.png)\n",
    "\n",
    "![](img_64.png)\n",
    "\n",
    "![](img_65.png)\n",
    "\n",
    "\n",
    "### Observación.\n",
    "\n",
    "Para este caso de ejemplo no es necesario tener una conexión bidireccional mediante dos grupos de seguridad entre una EC2 y una instancia de RDS.\n",
    "\n",
    "Sin embargo puede ser utili cuando la instancia de RDS necesita enviar datos a la EC2 o a otro servicio. Por ejemplo, si la instancia de RDS está ejecutando un servicio de correo electrónico y necesita enviar correos electrónicos a los usuarios, puede agregar una regla de entrada al grupo de seguridad de la EC2 o de otro servicio que permita el tráfico desde la instancia de RDS.\n",
    "\n",
    "https://aws.amazon.com/blogs/database/using-database-mail-on-amazon-rds-for-sql-server/\n",
    "\n",
    "En general, es suficiente tener un grupo de seguridad con acceso desde la EC2 hacia RDS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319757d6",
   "metadata": {},
   "source": [
    "## <a name=\"mark_05\"></a>Estrategias de backup\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "\n",
    "![](img_66.png)\n",
    "\n",
    "### Manuales:\n",
    "\n",
    "Son responsabilidad de quien administra la db (al ser snapshots son incrementales), podemos llevar estos back-up manuales de una zona a otra, o de una región a otra.\n",
    "\n",
    "### Automaticas:\n",
    "\n",
    "En ambientes productivos es conveniente realizar despliegues con multi-AZ, ya que si una db se encuentra sin disponibilidad tenemos una segunda de respaldo.\n",
    "\n",
    "### Precio:\n",
    "\n",
    "Los back-ups dependen de la db (el back-up va a usar un almacenamiento), con lo cual el pricing va a estar determinado por ese almancenamiento que va a usar la db. Recordar que la retención es de 0 - 35 días."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a3e20",
   "metadata": {},
   "source": [
    "## <a name=\"mark_06\"></a> Demo - Restauración de un back-up automático en RDS.\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Ingresamos a AWS --> RDS --> Instancias\n",
    "\n",
    "![](img_67.png)\n",
    "\n",
    "![](img_68.png)\n",
    "\n",
    "![](img_69.png)\n",
    "\n",
    "![](img_71.png)\n",
    "\n",
    "![](img_72.png)\n",
    "\n",
    "### Importante:\n",
    "\n",
    "`*************************************************************************************************************************`\n",
    "\n",
    "El identificador de instancia de base de datos se genera automáticamente cuando se crea una instancia de base de datos de RDS. Sin embargo, al momento de realizar un \"Restore to point in time\" tenemos que definirlo porque necesitamos especificar la instancia de base de datos de la que queremos restaurar los datos.\n",
    "\n",
    "Cuando realizamos un \"Restore to point in time\", estamos restaurando los datos de una instantánea de la base de datos. Las instantáneas de la base de datos se almacenan en Amazon S3 y se identifican por un nombre de instantánea. El identificador de instancia de base de datos se utiliza para identificar la instancia de base de datos de la que se creó la instantánea.\n",
    "\n",
    "Por ejemplo, si tenemos una instancia de base de datos de RDS con el identificador de instancia de base de datos \"my-db-instance\" y creamos una instantánea de la base de datos con el nombre de instantánea \"2023-07-20-12-00-00\". Si queremos restaurar los datos de esta instantánea a un punto en el tiempo específico, necesitamos especificar el identificador de instancia de base de datos \"my-db-instance\" y el nombre de la instantánea \"2023-07-20-12-00-00\".\n",
    "\n",
    "El siguiente es un ejemplo de cómo se puede especificar el identificador de instancia de base de datos al realizar un \"Restore to point in time\":\n",
    "\n",
    "\n",
    "aws rds restore-db-instance-from-snapshot --instance-identifier my-db-instance --snapshot-identifier 2023-07-20-12-00-00 --restore-time 2023-07-20T12:00:00Z\n",
    "\n",
    "\n",
    "Este comando restaurará los datos de la instancia de base de datos \"my-db-instance\" a su estado a las 12:00:00 UTC del 20 de julio de 2023.\n",
    "\n",
    "`*************************************************************************************************************************`\n",
    "\n",
    "El back-up será restaurado en esta VPC, en otra VPC, si será de acceso público, en que grupo de sub-red, y la zona de disponibilidad.\n",
    "\n",
    "![](img_73.png)\n",
    "\n",
    "![](img_74.png)\n",
    "\n",
    "![](img_75.png)\n",
    "\n",
    "![](img_76.png)\n",
    "\n",
    "Como se pudo observar en las imagenes, durante el restablecimiento de un back-up también se pueden cambiar las configuraciones establecidas para la db inicial.\n",
    "\n",
    "Una técnica alternativa es convinar back-up manuales con snapshot automáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a20309",
   "metadata": {},
   "source": [
    "## <a name=\"mark_07\"></a> Estrategias de performance en RDS\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_77.png)\n",
    "\n",
    "Para el monitoreo tenemos Cloudwatch y también al ingresar a la db tenemos un dashboard que nos muestra un monitoreo. Otra métrica importante a monitorear es la cantidad de conexiones, porque determina la carga de concurrencia que tiene nuestra db.\n",
    "\n",
    "La mejor estrategia para mejorar la performance de nuestra db son las replicas de lectura, para esto se sacar una replica \"B\" (completamente ascincrona) de mi db de producción \"A\", donde \"B\" será de solo lectura, como \"B\" tiene un nuevo endpoint, tenemos que configurar nuestra app para que las operaciones de lectura sean mandadas al nuevo endpoint. Esto descomprime nuestra base de datos \"A\" para operaciones de escritura. Las dos ddbb se mantendran actualizadas de forma ascincrona.\n",
    "\n",
    "![](img_78.png)\n",
    "\n",
    "Otra de las opciones que nos brinda la red de replicas es que a futuro nostros podríamos romper la sincronización y generar una db completamente independiente.\n",
    "\n",
    "También podríamos a partir de una db maestra crear multiples replicas de lectura.\n",
    "\n",
    "En \"MySQL\" podemos generar replicas de una replica, tener en cuenta que como es una sincronización ascincrona una variable a tener en cuenta es la latencia.\n",
    "\n",
    "En definitiva vamos a utilizar una red de replicas cuando deseamos descomprimir la carga de nuestra db meastro.\n",
    "\n",
    "IMPORTANTE!!! estás replicas no estan disponibles para motores basados en Oracle y MSQL Server.\n",
    "\n",
    "A nivel del storage de la db también podemos mejorar utilizando \"provisioned IOPS\", nos permite tener altas operaciones de entrada y salida en la db principalmente para transacciones OLTP.\n",
    "\n",
    "![](img_79.png)\n",
    "\n",
    "Podríamos pensar en implementar una db en memoria, como ElastiCache, hacer un cache de la data más consultada, a nivel de ElastiCache tenemos que tener en cuenta que es una db en memoria, y dentro de ElastiCache podemos utilizar 2 motores MemCache y Redis, los casos de usos son completamente diferentes en cuanto a almacenamiento de datos, alta disponibilidad, y replicación dentro de los nodos dentro de ElastiCache.\n",
    "\n",
    "Otra mejora que podríamos implementar --> Imaginemos que tenemos una db con la instancia más grande disponible + 5 replicas de lectura + un ElastiCache, y aún así la db está completamente saturada con muchas solicitudes de lectura y escritura, la mejor opción para esto es tomar la db principal y empezar a dividirla en db más pequeñas\n",
    "\n",
    "A nivel de monitoreo tenemos la herramienta \"Performance Insights\" que nos provee unos dashboard de monitoreo y mejores prácticas (Cuando y que acciones tomar).\n",
    "\n",
    "Otras estratégias adicionales, podríamos, dependiendo el motor de la db (Postgres algunos plugin instalados, MariaDB tiene una optimización para queries), depende el motor podríamos optar por distintas optimizaciones. Otra opción podría ser realizar una migración heterogenea de MySQL hacia Aurora, en la cual, según los datos de AWS el rendimiento puede aumentar hasta 5 veces. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0d1f2",
   "metadata": {},
   "source": [
    "## <a name=\"mark_08\"></a> Despliegues Multi AZ\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_80.png)\n",
    "\n",
    "Como se observa en la imagen, tenemos nuestra base de datos principal en la zona 1 y nuestra replicación en la zona 2, todo en la misma región, si tenemos problemas con la bd principal AWS realiza el cambio a la db en standby, tener en cuenta que la sincronización en este caso es sincronica, para este caso el endpoint de la db principal se moverá a la segunda db sin que nosotros tengamos que realizar cambios en nuestra app (failover = tolerancia ante fallos).\n",
    "\n",
    "### Características en Multi-AZ:\n",
    "\n",
    "![](img_81.png)\n",
    "\n",
    "Esto es para incrementar la disponibilidad de nuestra db, por eso \"siempre\" los despliegues de RDS para ambientes productivos se deben hacer con Multi-AZ.\n",
    "\n",
    "Conmutación por error, cuando detecta el error realiza el cambio a nuestra db standby.\n",
    "\n",
    "Recordar que deben ser zonas de disponibilidad distintas dentro de una misma región.\n",
    "\n",
    "### Importante!!!\n",
    "\n",
    "No confundir Multi-AZ con Replicas de lectura, las replicas de lectura estan diseñadas para performance, el Multi-AZ está diseñado para alta disponibilidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c71c3b",
   "metadata": {},
   "source": [
    "## <a name=\"mark_09\"></a> Estrategias de migración a RDS\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Como podemos desde una db, ya sea on-premise, en otro cloud provider, o en otro motor de db dentro de AWS, migrar al servicio de RDS o a otros servicios de ddbb dentro de AWS (Redshift data warehouse, DinamoDB NoSQL), utilizando la herramienta Data Base Migration Service (DMS). \n",
    "\n",
    "Estas estrategás de migración usan Data Base Migration Service.\n",
    "\n",
    "### Características:\n",
    "\n",
    "![](img_82.png)\n",
    "\n",
    "No afecta la db principal durante la migración.\n",
    "\n",
    "Durante la migración el servicio es capás de adaptar las cargas de trabajo automaticamente.\n",
    "\n",
    "Solo pagamos por los recursos que se esten usando durante la migración.\n",
    "\n",
    "Conmutación por error, automaticamente si encuentra errores en el proceso de migración o el destino de migración automaticamente puede generar una nueva instancia para continuar con el proceso.\n",
    "\n",
    "El proceso se realiza con encriptación en transito (Desde la fuente hasta el destino), y finalmente en destino podemos habilitar el cifrado con KMS. \n",
    "\n",
    "![](img_83.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65125eb1",
   "metadata": {},
   "source": [
    "## <a name=\"mark_10\"></a> Migraciones homogéneas y heterogéneas\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "\n",
    "Las migraciones homogéneas son migraciones en donde la base de datos de origen y la de destino pueden tener **diferentes versiones del mismo motor** o son **bases de datos compatible entre sí (MySQL-Aurora, o PostgreSQL-Aurora, por ejemplo)**.\n",
    "\n",
    "![](img_84.png)\n",
    "\n",
    "También podemos realizar migraciones heterogéneas, en donde la base de datos de origen no es compatible con la de destino.\n",
    "\n",
    "Estas migraciones no siempre son posibles, y antes de realizar la migración, en un primer paso vamos a necesitar convertir el esquema de la base de datos con la herramienta AWS Schema Conversion Tool para generar compatibilidad, y en un segundo paso ya podemos usar DMS.\n",
    "\n",
    "![](img_85.png)\n",
    "\n",
    "![](img_86.png)\n",
    "\n",
    "### Observación:\n",
    "\n",
    "Actualmente lo que Amazon tiene como compatibilidad esta en el recuadro \"Base de Datos\", pero observar que en ese recuadro también hay otro cloud provider, Data Warehouses (Redshift) y Storages (S3), DB2 (Que no pertenece a RDS), ddbb NoSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4d3a6",
   "metadata": {},
   "source": [
    "## <a name=\"mark_11\"></a> Casos de uso de RDS\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Cuando hablamos del \"servicio de RDS\", nos referimos a los casos para los 6 motores de db vistos.\n",
    "\n",
    "El dominio mediante Route 53 se conecta a un balanceador externo, que distribuye la carga a dos zonas de disponibilidad diferentes en instancias que están en una sub red pública, también vamos a contar con un balanceador interno en la parte de la app que tenemos en la sub red privada, y por último, a nivel de sub red privada tenemos nuestra ddbb RDS con un Multi-AZ, tenemos una M (master), S (Standaby), y R (Replicas de lectura). Este esquema funciona perfectamente para un sitio web que requiera alta disponibilidad el cual va a estar distribuido en \"capa web\" --> \"capa app\" --> \"capa ddbb\"\n",
    "\n",
    "![](img_87.png)\n",
    "\n",
    "Otro caso de uso, mucho más sencillo, es un sitio web, en este caso tenemos nuestro dominio \"misite.com\" que está en el servicio de DNS de Amazon llamado Route 53, tenemos un balanceador de carga que distribuye la carga en 2 instancias que van a tener nuestra app/ nuestro servidor web, y estas 2 instancias van a estar conectadas a la misma db, todo en una única zona de disponibilidad.\n",
    "\n",
    "![](img_88.png)\n",
    "\n",
    "El siguiente caso de uso, consta de una db on-premise (MSQL Server), usando S3 para el almacenamiento de los archivos de back-up (archivos .bak), y a partir de esos mismos archivos restaurar la misma db pero en la nube.\n",
    "![](img_89.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcc4c2",
   "metadata": {},
   "source": [
    "## <a name=\"mark_12\"></a> Introducción a Aurora\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Aurora (db relacional desarrollado por AWS) es el motor de db más robusto que tiene AWS a nivel relacional y es uno de los principales por sus características.\n",
    "\n",
    "![](img_90.png)\n",
    "\n",
    "Un rendimiento garantizado superior a MySQL y Postgres, a nivel de rendimiento y alta disponibilidad de funcionamiento es la más robusta que hay en el servicio de RDS. Soporta hasta 64TB de Storage, puede contar con 15 replicas de lectura en distintas zonas de disponibilidad, con valores inferiores a 10ms entre el master y la replica, monitoreo y failover menor a 30ms.\n",
    "\n",
    "Cuando uno crea una db Aurora crea un Cluster de ddbb, este cluster se compone de una instancia Maestra y multiples replicas de lectura (pueden ser hasta 15), todas desplegadas en diferentes zonas de disponibilidad (la cantidad de zonas de disponibilidad va a depender de la región en la cual despleguemos nuestra db Aurora, hay regiones con 3 zonas de disponibilidad como hay regiones que tienen 6 zonas de disponibilidad), como vemos en el gráfico la instancia M va a cumplir funciones de lectura y escritura sobre los datos replicados en distintas zonas de disponibilidad, entonces va a tener la data separada en distintas zonas de disponibilidad, y vamos a contar con replicas de lectura en todas las zonas de disponibilidad dependiendo de la cantidad de replicas que escojamos en la creación de la db.\n",
    "\n",
    "Las replicas de lectura, solo van a leer desde las copias del storage que hay en las zonas de disponibilidad.\n",
    "\n",
    "Al momento de la creación de una db, podemos especificar la prioridad de la replica de lectura, de esa forma en caso de fallos del maestro, la replica puede reemplazar al maestro.\n",
    "\n",
    "Al nivel de la data, como se encuentra replicada en diferentes zonas de disponibilidad, esas replicas estaran disponibles ante fallos.\n",
    "\n",
    "![](img_91.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3036f6",
   "metadata": {},
   "source": [
    "## <a name=\"mark_13\"></a> Características de Aurora\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Aurora cuenta con 3 tipos de endpoints.\n",
    "\n",
    "![](img_92.png)\n",
    "\n",
    "### Endpoint a nivel de db principal/maestro:\n",
    "\n",
    "El primero está orientado a la db principal/maestro, este endpoint es el que va a administrar el cluster y donde vamos a especificar las solicitudes de escritura y lectura y está compuesto por \"mydbcluster.cluster-identificador.la_region_del_servicio:puerto\". Funcionalidades que se adjuntan son el tipo de storage y el despliegue en diferentes zonas de disponibilidad.\n",
    "\n",
    "### Endpoint a nivel de instancia y Replica:\n",
    "\n",
    "![](img_93.png)\n",
    "\n",
    "Amazon nos brinda un tercer Endpoint, el \"endpoint de instancia\", el cual identifica cada instancia con un endpoint --> instancia Master, e instancias replica. Cada replica va a tener su propio endpoint \"para solicitudes de lectura\".\n",
    "\n",
    "\n",
    "Pero hay una diferencia fundamental, entre el endpoint de instancia, replica, y Master. AWS recomienda que utilicemos el endpoint del Master, y la replica, no recomienda que usemos el endpoint de instancia, sin embargo con el endpoint de instancia podemos ajustar cargas especificas a las replicas, manejando así el balance entre las replicas, cosa que no nos permiten los endpoint de las replicas.\n",
    "\n",
    "En el siguiente diagrama especificamos la diferencia entre los endpoints.\n",
    "\n",
    "_ Tenemos el Cluster endpoint que apunta a la db Master, se encarga de la lectura, escritura y leer las replicas.\n",
    "\n",
    "_ El Reder Endpoint va a estar en cada una de las replicas de lectura.\n",
    "\n",
    "_ En Endpoint de instancia (el cual no figura en el gráfico) nos permite tener un endpoint \"distinto\" para cada instancia.\n",
    "\n",
    "![](img_94.png)\n",
    "\n",
    "\n",
    "### Otras características importantes:\n",
    "\n",
    "![](img_95.png)\n",
    "\n",
    "Otra opción para la Recuperación de accidentes también se puede especificar que no tome una replica para promover instancia principal, sino que regenere la instancia principal.\n",
    "\n",
    "## <a name=\"mark_14\"></a> Casos de uso Aurora\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "En esta arquitectura Real Time, tenemos una db no relacional produciendo información en tiempo real, información que se va ingestando y se entrega como Streaming, esta información viaja a través de una función a un servicio que se llama \"Kinesis Firehose\" este servico se encarga de procesar una información utilizando una Lambda de transformación (quiero recibir determinados campos y mostrarlos de una forma en particular), luego se pasa a un sistema de almacenamiento (como S3), teniendo la información que no se transformó (se envia notificaciones a travéz de SNS) y la información transformada, de esa información tenemos otra función que se encarga de ingestarla a una db Aurora desplegada en 2 zonas de disponibilidad completamente diferentes, luego podemos alimentar otros servicios en Real Time.\n",
    "\n",
    "Aurora es utilizado donde se requiera alta disponibilidad y alto rendimiento\n",
    "\n",
    "![](img_96.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb581e04",
   "metadata": {},
   "source": [
    "## <a name=\"mark_15\"></a> Aurora Serverless\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Hasta el momento es la única db autoescalable que hay en el mercado, pudiendo configurar una capacidad mínima y una capacidad máxima, a medida que la concurrencia va creciendo, esta capacidad mínima va creciendo hasta la capacidad máxima que hallamos especificado, el escalamiento y desescalamiento será automatico dependiendo la demanda.\n",
    "\n",
    "### Importante!!! Monitorear el costo al usar este servicio.\n",
    "\n",
    "![](img_97.png)\n",
    "\n",
    "### Funcionamiento:\n",
    "\n",
    "Proxy fleet --> es como un endpoint, este proxy se encarga de medir la concurrencia a la app, dependiendo esa concurrencia la db crecerá o decrecerá, también la db tiene la funcionalidad \"warm-pool of capacity\" precalentamiento de las instancias para que puedan ir creciendo con la demanda.\n",
    "\n",
    "![](img_98.png)\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "    - Pricing.\n",
    "    - Tiempo de respuesta podemos crecer en replicas con tiempos inferiores a 5seg.\n",
    "    - Monitoreo, se puede integrar con Couldwatch.\n",
    "    - En momento de inactividad, no hay consumo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b86a",
   "metadata": {},
   "source": [
    "## <a name=\"mark_16\"></a> Creación de DB Aurora, equivalencias con RDS.\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Dentro de RDS --> Create Database, elegimos Amazon Aurora, al final veremos las compatibilidades que tiene, podemos observar que tiene compatibilidad con:\n",
    "\n",
    "    - MySQL 5.6 --> Es compatible y cuenta con Aurora Serveless y Capacidad de Queries paralelas.\n",
    "    \n",
    "    - MySQL 5.7 --> Es compatible pero No cuenta con esa característica.\n",
    "    \n",
    "    - PostgresSQL --> Es compatible pero No cuenta con esa característica.\n",
    "\n",
    "![](img_99.png)\n",
    "\n",
    "Elegimos MySQL 5.6 compatible y damos en Next.\n",
    "\n",
    "![](img_100.png)\n",
    "\n",
    "Provisioned: Nosotros aprovisionamos y manejamos las instancias.\n",
    "\n",
    "Provisiones con Aurora parallel y query enabled: Nosotros aprovisionamos y manejamos las instancias, sin embargo permitimos que Aurora nos ayude con el performance y la analítica a nivel de procesamiento en las queries.\n",
    "\n",
    "Serverless: Tendremos que definir un \"DB Cluster Identifier\" , un \"Master username\", y un \"Master password\" (será el Password de nuestra db)\n",
    "\n",
    "Elegimos \"Provitioned\" y comenzamos definiendo el tamaño de la instancia y Multi-AZ.\n",
    "\n",
    "![](img_101.png)\n",
    "\n",
    "![](img_102.png)\n",
    "\n",
    "![](img_103.png)\n",
    "\n",
    "Recordar que el grupo de seguridad tendrá los puertos permitidos (regla) para comunicarnos con la db, se recomienda un grupo de seguridad por db.\n",
    "\n",
    "![](img_104.png)\n",
    "\n",
    "![](img_105.png)\n",
    "\n",
    "En Failover, tenemos hasta 15 replicas de lectura, con una prioridad para que en caso de una falla esa replica sea promovida a instancia primaria.\n",
    "\n",
    "![](img_106.png)\n",
    "\n",
    "![](img_107.png)\n",
    "\n",
    "![](img_108.png)\n",
    "\n",
    "![](img_109.png)\n",
    "\n",
    "Performance insight: recomendaciones de buenas practicas y monitoreo.\n",
    "\n",
    "![](img_110.png)\n",
    "\n",
    "![](img_111.png)\n",
    "\n",
    "Deletion Protection: es una funcionalidad que evita el borrado accidental de una db, para poder borrar la bd debemos ir a la db y desactivar esta función.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a33994",
   "metadata": {},
   "source": [
    "## <a name=\"mark_17\"></a> Características de DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_112.png)\n",
    "\n",
    "Es posible programar el auto-escalamiento y modificar sus propiedades de lectura y escritura para que pueda crecer de acuerdo a nuestras necesidades.\n",
    "\n",
    "![](img_113.png)\n",
    "\n",
    "DinamoDB se basa en dos conceptos importantes:\n",
    "\n",
    "    - Las unidades de lectura o RCU se basan en bloques de 4Kb/seg.\n",
    "    \n",
    "    - Las unidades de escritura o WCU se basan en bloques de 1Kb/seg.\n",
    "\n",
    "Saber esto es importante porque al momento de estar creando la db, tendremos que especificar la capacidad de lectura y escritura, ya que en base a estos dos 2 parámetros se determina el costo de la db. También es utilizado cuando tengamos que especificar el auto-escalamiento de la db.\n",
    "\n",
    "![](img_114.png)\n",
    "\n",
    "Anatomía de DynamoDB\n",
    "\n",
    "- Tables --> Unidad fundamental, es una colección de datos\n",
    "\n",
    "- Items --> Es una colección de atributos que pueden identificarse de forma exclusiva entre todos los demás elementos\n",
    "\n",
    "- Attributes - Es un componente fundamental de los datos, los cuales pueden estar anidados hasta 32 niveles de profundidad.\n",
    "\n",
    "![](img_115.png)\n",
    "\n",
    "- Partición --> Espacio de almacenamiento en el cual vamos a guardar la información, estas particiones están guiadas por una llave, cuando necesitemos la \"partition key\" toda la información que tenemos en la tabla se va a almacenar en el storage tomando como base lo que especificamos como \"llave de partición\", por ejempo el id del trabajador. Entonces tomará el id del trabajador, realizará una función hash y con base en eso es que lo va a almacenar en el storage. Por eso una recomendación cuando tenemos una bd con muchos elemento y muy pesada, es que el partition key sea lo más random posible para que no todo quede almacenado en los mismos sectores del disco.\n",
    "\n",
    "![](img_116.png)\n",
    "\n",
    "- También tenemos otro tipo de llaves \"sort key\" cumple la función del GROUP BY\n",
    "\n",
    "### Combinaciones para mejorar la performance de nuestras consultas:\n",
    "\n",
    "![](img_117.png)\n",
    "\n",
    "![](img_118.png)\n",
    "\n",
    "### Tabla en DynamoDB:\n",
    "\n",
    "![](img_119.png)\n",
    "\n",
    " **En el contexto de DynamoDB, a continuación se definen los términos mencionados en castellano:**\n",
    "\n",
    "**Clave principal (Primary Key):**\n",
    "\n",
    "- Es un atributo o conjunto de atributos que identifica de forma única cada elemento de una tabla de DynamoDB.\n",
    "- Debe ser única para cada elemento y no puede ser nula.\n",
    "- Determina cómo se distribuyen los datos en las particiones de la tabla.\n",
    "- Hay dos tipos de claves principales: clave de partición y clave de partición + clave de ordenación.\n",
    "\n",
    "**Clave de partición (Partition Key):**\n",
    "\n",
    "- Es el primer atributo de la clave principal.\n",
    "- DynamoDB utiliza la clave de partición para distribuir los datos en las particiones de la tabla.\n",
    "- Los elementos con la misma clave de partición se almacenan en la misma partición.\n",
    "\n",
    "**Clave de partición + Clave de ordenación (Partition Key + Sort Key):**\n",
    "\n",
    "- Es un tipo de clave principal que consta de dos atributos: la clave de partición y la clave de ordenación.\n",
    "- La clave de ordenación se utiliza para ordenar los elementos dentro de cada partición.\n",
    "- Los elementos con la misma clave de partición, pero diferentes claves de ordenación, se almacenan en la misma partición, pero se ordenan de acuerdo con la clave de ordenación.\n",
    "\n",
    "**Índices secundarios (Secondary Indexes):**\n",
    "\n",
    "- Son estructuras de datos que permiten consultar los datos de una tabla de DynamoDB utilizando atributos que no forman parte de la clave principal.\n",
    "- DynamoDB admite dos tipos de índices secundarios: índices secundarios globales e índices secundarios locales.\n",
    "\n",
    "**Índice secundario global (Global Secondary Index):**\n",
    "\n",
    "- Es un índice que tiene su propia clave principal, que puede ser diferente de la clave principal de la tabla base.\n",
    "- Los índices secundarios globales pueden abarcar varias particiones de la tabla base.\n",
    "- Se utilizan para consultas que no se pueden satisfacer eficientemente con la clave principal de la tabla base.\n",
    "\n",
    "**Índice secundario local (Local Secondary Index):**\n",
    "\n",
    "- Es un índice que tiene la misma clave de partición que la tabla base, pero una clave de ordenación diferente.\n",
    "- Los índices secundarios locales solo abarcan una única partición de la tabla base.\n",
    "- Se utilizan para consultas que necesitan ordenar los elementos de una partición de forma diferente a la clave de ordenación de la tabla base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee3347",
   "metadata": {},
   "source": [
    "## <a name=\"mark_18\"></a> Consistencia en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Escenario: Estamos escribiendo en una db DynamoDB, como esta db está replicada en diferentes locaciones (estas almacenando información), la db entonces se distribuye en las diferentes particiones, que es el espacio de almacenamiento en diferentes locaciones, pero por alguna funcionalidad en especifico necesitamos que en el instante que la data se ingeste, otra app lea esa data inmediatamente, o estemos actualizando data y la app tenga que leer la última data, puede pasar que mientras se sobreescribe la data la consulta encuentre la data anterior, por lo cual nos enfrentamos a 2 tipos de consistencias.\n",
    "\n",
    "![](img_120.png)\n",
    "\n",
    "**La consistencia eventual** primero es a nivel de lectura de la tabla de DynamoDB, cuando consultamos la tabla, la respuesta NO muestra los resultados de una tarea de escritura reciente. Entonces, si acabamos de hacer una escritura la consulta no mostrará esta última escritura porque tenemos **consistencia eventual** (consume los 4Kb de bloque por seg)\n",
    "\n",
    "Qué pasa si necesitamos que al hacer la consulta tengamos la última escritura de la data?. Entonces aparece **La Concistencia Fuerte de Lectura**, esta técnica puede acceder a la última escritura realizada, pero consume el doble de la **consistencia eventual**, por supuesto esto elevará el pricing\n",
    "\n",
    "![](img_121.png)\n",
    "\n",
    "puede mostrar los resultados de una tarea de escritura reciente cuando consultamos una tabla recién actualizada, además, consume los 4kb de bloques por segundo en las unidades de lectura.\n",
    "\n",
    "Este tipo de consistencia es el adecuando para aplicaciones y casos de uso muy específicos donde la consulta y la escritura deben estar tan sincronizadas como sea posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a42363",
   "metadata": {},
   "source": [
    "## <a name=\"mark_19\"></a> Creando nuestra primer tabla en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Consola de AWS --> DynamoDB --> Crear Tabla\n",
    "\n",
    "![](img_122.png)\n",
    "\n",
    "por defecto el tilde de \"Usar configuración predeterminada\" se encuentra activo, pero esto nos quita flexibilidad, entonces lo destildamos.\n",
    "\n",
    "![](img_123.png)\n",
    "\n",
    "![](img_124.png)\n",
    "\n",
    "Para la capacidad aprovisionada, siempre es conveniente comenzar de pequeño, y setear el auto scaling para que vaya creciendo con el requerimiento.\n",
    "\n",
    "Objetivo de utilización --> es un porcentaje en el cual creemos que la db va a ser utilizada.\n",
    "\n",
    "![](img_125.png)\n",
    "\n",
    "Recordar que para realizar el autoescalamiento debemo contar con el role habilitador.\n",
    "\n",
    "![](img_126.png)\n",
    "\n",
    "Cifrado en reposo, solo en Advanced Setting.\n",
    "\n",
    "![](img_127.png)\n",
    "\n",
    "Tabla Trabajadores creada...\n",
    "\n",
    "![](img_128.png)\n",
    "\n",
    "![](img_129.png)\n",
    "\n",
    "En la parte de Elementos también podemos agregar \"items\" manualmente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786fe90f",
   "metadata": {},
   "source": [
    "## <a name=\"mark_20\"></a> Casos de uso en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_130.png)\n",
    "\n",
    "IoT --> por el tema de Real Time, por la capacidad de ingesta que tiene de IoT.\n",
    "\n",
    "Web --> Almacenamiento de sesiones.\n",
    "\n",
    "Gaming --> Por su alta disponibilidad, y al no ser relacional es un caso muy bueno de uso.\n",
    "\n",
    "RealTime --> A medida que ingestemos utilicemos esa data para otras arquitecturas.\n",
    "\n",
    "Caso de uso particular, tenemos una cola y tenemos un endpoint para ingestar información al endpoint, pero el endpoint está caído, entonces la cola principal manda las solicitudes a una cola de carta muerta, esta cola de carta muerta habilita una función lambda que toma la información y la ingesta en Dynamo, de esta forma cuando el endpoint se encuentre nuevamente online desde dynamo se realiza la re-ingesta, en este escenario no tenemos perdida de información, ya que fue almacenada en Dynamo como data no estructurada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c7d9b",
   "metadata": {},
   "source": [
    "## <a name=\"mark_21\"></a> Índices y particiones en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "### Organización de la información con \"claves simples\":\n",
    "\n",
    "![](img_131.png)\n",
    "\n",
    "![](img_132.png)\n",
    "\n",
    "Asignación --> Asignación de espacio de acuerdo a las llaves, id_trabajador, con base a este id realizará una función hash para almacenar y determinar en que espacio de almacenamiento o partición va a almacenar esta información, todo se basará en esta clave principal también las consultas y la recuperación de información al momento de realizar la query.\n",
    "\n",
    "Como se ve en la siguiente imagen, dependiendo la clave principal la función hash va distribuyendo la información en diferentes partinciones (asignación en disco), si la características de las claves principales (en 100mil usuarios) son muy parecidas, ejemplo 123_juan, 123_pedro, etc esta información quedará repartida en espacios de disco similires o muy cercanos y esto afectará nuestra performance, por ese motivo es mejor que estas llaves/claves principales sean mucho más random, para evitar esto.\n",
    "\n",
    "![](img_133.png)\n",
    "\n",
    "Sin embargo está distribución se encuentra determinada por la capacidad de storage, RCU y WCU.\n",
    "\n",
    "![](img_134.png)\n",
    "\n",
    "En el contexto de DynamoDB, es importante que una clave principal sea lo más aleatoria posible porque ayuda a garantizar que los datos se distribuyan de manera uniforme en las particiones de la tabla. Esto es importante para el rendimiento, ya que las particiones se pueden distribuir en diferentes servidores.\n",
    "\n",
    "Una clave principal aleatoria también ayuda a garantizar que los datos sean íntegros. Si dos elementos tienen la misma clave principal, DynamoDB no podrá distinguirlos y los datos se corromperán.\n",
    "\n",
    "Aquí hay algunas razones específicas por las que es importante que una clave principal sea lo más aleatoria posible:\n",
    "\n",
    "* **Mejora el rendimiento:** Cuando los datos se distribuyen de manera uniforme en las particiones, DynamoDB puede distribuir las operaciones de lectura y escritura de manera uniforme entre los servidores. Esto puede mejorar el rendimiento de las aplicaciones que acceden a los datos de DynamoDB.\n",
    "* **Mejora la integridad de los datos:** Si dos elementos tienen la misma clave principal, DynamoDB no podrá distinguirlos. Esto puede provocar que los datos se corrompan. Una clave principal aleatoria ayuda a garantizar que no se produzcan colisiones de claves.\n",
    "* **Facilita la migración de datos:** Si necesita migrar datos de una tabla de DynamoDB a otra, una clave principal aleatoria puede facilitar el proceso. Esto se debe a que los datos se distribuirán de manera uniforme en ambas tablas.\n",
    "\n",
    "Hay algunas cosas que puede hacer para asegurarse de que las claves principales de sus tablas de DynamoDB sean lo más aleatorias posible:\n",
    "\n",
    "* **Utilice un generador de números aleatorios:** Hay muchas bibliotecas disponibles que pueden generar números aleatorios. Puede utilizar una de estas bibliotecas para generar las claves principales de sus elementos.\n",
    "* **Utilice un algoritmo de hash:** Un algoritmo de hash puede convertir una cadena de texto en una cadena de longitud fija. Puede utilizar un algoritmo de hash para generar claves principales aleatorias para sus elementos.\n",
    "* **Evite utilizar valores que puedan ser predecibles:** Evite utilizar valores que puedan ser predecibles para sus claves principales. Por ejemplo, no utilice números secuenciales o valores basados en el tiempo.\n",
    "\n",
    "En general, es importante que las claves principales de sus tablas de DynamoDB sean lo más aleatorias posible. Esto ayudará a garantizar que los datos se distribuyan de manera uniforme, se mantengan íntegros y se puedan migrar fácilmente.\n",
    "\n",
    "En teoría, las consultas de DynamoDB pueden ser más lentas si los datos se encuentran distribuidos en diferentes servidores. Esto se debe a que DynamoDB tiene que buscar en cada servidor para encontrar los datos que está buscando.\n",
    "\n",
    "Sin embargo, en la práctica, DynamoDB está diseñado para optimizar el rendimiento de las consultas, incluso cuando los datos se encuentran distribuidos en diferentes servidores. DynamoDB utiliza un algoritmo de búsqueda distribuido que puede buscar de manera eficiente en los datos de múltiples servidores.\n",
    "\n",
    "Además, DynamoDB utiliza un mecanismo llamado \"sharding\" para distribuir los datos de manera uniforme en los servidores. Esto ayuda a garantizar que las consultas se distribuyan de manera uniforme entre los servidores, lo que puede mejorar el rendimiento.\n",
    "\n",
    "En general, las consultas de DynamoDB no suelen ser más lentas si los datos se encuentran distribuidos en diferentes servidores. Sin embargo, hay algunas cosas que puede hacer para mejorar aún más el rendimiento de las consultas, como:\n",
    "\n",
    "* **Utilice una clave principal lo más aleatoria posible:** Esto ayudará a garantizar que los datos se distribuyan de manera uniforme en los servidores.\n",
    "* **Establezca una partición de caché:** Esto puede ayudar a reducir el número de veces que DynamoDB tiene que buscar en los datos de los servidores.\n",
    "* **Utilice un punto de acceso regional:** Esto puede ayudar a reducir la latencia de las consultas.\n",
    "\n",
    "### Organización de la información con \"claves compuestas\":\n",
    "\n",
    "![](img_135.png)\n",
    "\n",
    "Clave de \"ordenación\"/ordenamiento --> Sort Key\n",
    "\n",
    "La primer llave determinará la partición y la segunda el orden dentro de la partición.\n",
    "\n",
    "![](img_136.png)\n",
    "\n",
    "### Importante:\n",
    "\n",
    "Si utilizamos una llave de partición como clave principal y una segunda llave de ordenamiento (sort key) combinadas, entonces sí es posible que la clave principal sea la misma en diferentes elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b927b90",
   "metadata": {},
   "source": [
    "## <a name=\"mark_22\"></a> Operaciones Scan en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_137.png)\n",
    "\n",
    "Al realizar una consulta consumira muchas RCU, muchas más que una consulta especifica.\n",
    "\n",
    "Scan no es recomendado!!!.\n",
    "\n",
    "![](img_138.png)\n",
    "\n",
    "### Recomendaciones desde AWS.\n",
    "\n",
    "![](img_139.png)\n",
    "\n",
    "Es mucho mejor hacer operaciones pequeñas que operaciones muy grandes.\n",
    "\n",
    "![](img_140.png)\n",
    "\n",
    "Duplicamos para no sobrecargar la tabla principal o productiva.\n",
    "\n",
    "Visualización de la consulta Scan en DynamoDB:\n",
    "\n",
    "![](img_141.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446658a",
   "metadata": {},
   "source": [
    "## <a name=\"mark_23\"></a> Operaciones Query en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_142.png)\n",
    "\n",
    "![](img_143.png)\n",
    "\n",
    "![](img_144.png)\n",
    "\n",
    "![](img_145.png)\n",
    "\n",
    "![](img_146.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0aced",
   "metadata": {},
   "source": [
    "## <a name=\"mark_24\"></a> Demo de operaciones Scan y Query en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_147.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f3099",
   "metadata": {},
   "source": [
    "## <a name=\"mark_25\"></a> ¿Qué es Local Seconday Index?\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "En una tabla de Dynamo cada ítem debe contener una clave primaria única. Esta llave debe tener una clave de partición y opcionalmente puede tener una range key (Sort Key). Dentro de la partición, los ítems son ordenados por la range key, en los casos donde la información que necesitemos coincida con nuestra range key el acceso a los elementos va a ser mucho más rápido.\n",
    "\n",
    "![](img_148.png)\n",
    "\n",
    "![](img_149.png)\n",
    "\n",
    "Sin embargo se presentan casos en los cuales la información que necesitamos se encuentra en otro atributo totalmente diferente a la range key, para estos casos podemos utilizar un Local Secondary Index (LSI) el cual tiene la misma clave de partición pero puede tener una range key completamente diferente (por tabla se pueden crear hasta 5 LSI), se debe tener en cuenta que los LSI solamente se pueden crear al momento de crear la tabla, una vez creada no se podrán crear LSI.\n",
    "\n",
    "![](img_150.png)\n",
    "\n",
    "Por ejemplo si tenemos la una tabla que mantiene el puntaje de jugadores en diferentes juegos online.\n",
    "\n",
    "La tabla Scores está conformada de la siguiente forma:\n",
    "\n",
    "Llave de partición: GameName → Nombre del Juego\n",
    "\n",
    "Llave de ordenamiento (Range o Sort Key): LastGameMatch → Fecha de la última partida disputada en el juego.\n",
    "\n",
    "![](img_151.png)\n",
    "\n",
    "Para la tabla SCORE podríamos obtener información de los juegos y la fecha de la última partida disputada en el juego por diferente usuario.\n",
    "\n",
    "Ahora supongamos que necesitamos responder preguntas diferentes como:\n",
    "\n",
    "¿Cuál es el puntaje máximo en un determinado juego?\n",
    "\n",
    "¿Cuál es la partida ganada más antigua en el juego?\n",
    "\n",
    "No sería posible obtener la información solicitada con los índices que se tienen actualmente, tendríamos que hacer una operación SCAN que consumiría muchas unidades de lectura.\n",
    "\n",
    "Para este caso la mejor solución sería utilizar LSI:\n",
    "\n",
    "GameName y Score.\n",
    "\n",
    "GameName y LastWin.\n",
    "\n",
    "Con estos LSI podríamos consultar la data con la misma llave de partición (GameName) y obtener resultados sobre otras llaves range como Score y LastWin. Esto nos ayudaría en nuestra tabla a obtener los datos que necesitamos de forma más eficiente y también evitamos el consumo de unidades de lectura de la tabla RCU lo cual se verá reflejado en un ahorro de costos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff51de0",
   "metadata": {},
   "source": [
    "## <a name=\"mark_26\"></a> Características Streams y Replicación en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "DynamoDB Streams es una funcionalidad adicional al momento de contar con DynamoDB como un proveedor de datos RealTime en una arquitectura.\n",
    "\n",
    "![](img_152.png)\n",
    "\n",
    "Por ejemplo, tenemos una tabla en la cual necesitamos monitorear siempre todo lo que se va ingestando en determinado campo, DynamoDB va a mantener el registro de todo lo que se va a estar ingestando (en un chache/log) para que después esa información pueda ser procesada o consumida por otra app en tiempo real, y mantendrá el orden en el que se ejecutaron los cambios, para que con ese orden podamos alimentar otros servicios de AWS.\n",
    "\n",
    "![](img_153.png)\n",
    "\n",
    "![](img_154.png)\n",
    "\n",
    "La imagen se muestra un diagrama de un sistema de base de datos dinámico. El sistema consta de los siguientes componentes:\n",
    "\n",
    "* **Aplicación:** La aplicación es la capa de software que interactúa con la base de datos.\n",
    "* **AWS SDK:** El AWS SDK es una biblioteca de software que proporciona una interfaz para interactuar con los servicios de AWS, incluido DynamoDB.\n",
    "* **DynamoDB:** DynamoDB es un servicio de base de datos de NoSQL que proporciona un almacenamiento de datos escalable y altamente disponible.\n",
    "* **Streams:** DynamoDB Streams es un servicio que captura las modificaciones realizadas en los elementos de una tabla de DynamoDB.\n",
    "\n",
    "La aplicación utiliza el AWS SDK para conectarse a DynamoDB y realizar operaciones de lectura y escritura en la base de datos. Las modificaciones realizadas en los elementos de la base de datos se capturan en DynamoDB Streams.\n",
    "\n",
    "En el diagrama, la aplicación está enviando una solicitud para crear un nuevo elemento en la tabla de DynamoDB. El AWS SDK envía la solicitud a DynamoDB. DynamoDB crea el nuevo elemento y lo almacena en la tabla.\n",
    "\n",
    "La aplicación también está enviando una solicitud para leer un elemento existente de la tabla de DynamoDB. El AWS SDK envía la solicitud a DynamoDB. DynamoDB recupera el elemento de la tabla y lo devuelve a la aplicación.\n",
    "\n",
    "Las modificaciones realizadas en los elementos de la tabla de DynamoDB se capturan en DynamoDB Streams. Estas modificaciones se pueden utilizar para realizar tareas como:\n",
    "\n",
    "* **Notificar a los usuarios sobre las modificaciones realizadas en los datos.**\n",
    "* **Crear copias de seguridad de los datos.**\n",
    "* **Analizar los datos para identificar tendencias o patrones.**\n",
    "\n",
    "En el diagrama, DynamoDB Streams está capturando una modificación realizada en el elemento con la clave principal \"123456\". La modificación es una actualización del atributo \"name\" del elemento.\n",
    "\n",
    "En general, el sistema de base de datos dinámico que se muestra en la imagen es una forma flexible y escalable de almacenar datos. El sistema puede utilizarse para una variedad de aplicaciones, incluyendo aplicaciones de comercio electrónico, aplicaciones de análisis de datos y aplicaciones de IoT.\n",
    "\n",
    "Aquí hay algunos detalles adicionales sobre los componentes de la imagen:\n",
    "\n",
    "* **La aplicación:** La aplicación puede ser cualquier tipo de aplicación, desde una aplicación web hasta una aplicación móvil. La aplicación debe utilizar el AWS SDK para interactuar con DynamoDB.\n",
    "* **El AWS SDK:** El AWS SDK está disponible para una variedad de lenguajes de programación, incluyendo Java, Python, JavaScript y Go.\n",
    "* **DynamoDB:** DynamoDB es un servicio de base de datos NoSQL que proporciona un almacenamiento de datos escalable y altamente disponible. DynamoDB admite una variedad de tipos de datos, incluyendo números, cadenas, fechas y objetos JSON.\n",
    "* **Streams:** DynamoDB Streams es un servicio que captura las modificaciones realizadas en los elementos de una tabla de DynamoDB. DynamoDB Streams proporciona una secuencia de registros de transmisión que contiene información sobre las modificaciones realizadas en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0708b43",
   "metadata": {},
   "source": [
    "## <a name=\"mark_27\"></a> Casos de uso Streams y Replicación en DynamoDB\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_155.png)\n",
    "\n",
    "**BarkTable** es el nombre de una tabla de DynamoDB que almacena información sobre los ladridos de los perros. La tabla tiene dos atributos:\n",
    "\n",
    "* **id:** La clave principal de la tabla. Es un número único que identifica cada ladrido.\n",
    "* **text:** El texto del ladrido.\n",
    "\n",
    "**publishNewBark** es una función de AWS Lambda que se utiliza para publicar nuevos ladridos en el tema de Amazon SNS **wooferTopic**. La función recibe como entrada el id y el texto del ladrido.\n",
    "\n",
    "**wooferTopic** es un tema de Amazon SNS que se utiliza para notificar a los usuarios sobre los nuevos ladridos. Los usuarios pueden suscribirse al tema para recibir notificaciones por correo electrónico, SMS o mensajería instantánea.\n",
    "\n",
    "En el contexto de AWS, **BarkTable**, **publishNewBark** y **wooferTopic** se pueden utilizar para crear un sistema de notificación que notifica a los usuarios cuando se producen nuevos ladridos.\n",
    "\n",
    "Aquí hay un ejemplo de cómo se pueden utilizar estos componentes:\n",
    "\n",
    "Una aplicación móvil puede utilizar el AWS SDK para conectarse a la tabla **BarkTable** y crear nuevos elementos. Cuando se crea un nuevo elemento, la aplicación llama a la función **publishNewBark** para publicar el ladrido en el tema **wooferTopic**. Los usuarios que se hayan suscrito al tema recibirán una notificación por correo electrónico, SMS o mensajería instantánea con el texto del ladrido.\n",
    "\n",
    "Este sistema de notificación puede utilizarse para una variedad de propósitos, como:\n",
    "\n",
    "* **Notificar a los dueños de perros cuando sus perros están ladrando.**\n",
    "* **Recopilar datos sobre los ladridos de los perros para fines de investigación.**\n",
    "* **Crear aplicaciones que permitan a los usuarios interactuar con los ladridos de los perros.**\n",
    "\n",
    "### Importante la tabla podría guardar nuevos usuarios en vez de ladridos, y enviar mensajes sobre nuevos usuarios que se registran.\n",
    "\n",
    "![](img_156.png)\n",
    "\n",
    "Recordar que una función lambda ejecuta un código con una función particular.\n",
    "\n",
    "Para este ejemplo podría ser una lambda, que por ejemplo se active con lecturasa en un S3 y luego escriba en una DynamoDB, al momento otra lambda estaría tomando esta última escritura y escribiendo en otra DynamoDB, esto se puede interpretar como un proceso de replicación en una región diferente.\n",
    "\n",
    "![](img_157.png)\n",
    "\n",
    "Una notificación al cliente (el ícono de la computadora podría ser un servidor).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc9d40",
   "metadata": {},
   "source": [
    "## <a name=\"mark_28\"></a> DAX: DynamoDB Accelerator\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_158.png)\n",
    "\n",
    "Esto es un cluster de cache completamente administrado y de alta disponibilidad.\n",
    "\n",
    "![](img_159.png)\n",
    "\n",
    "Encriptación en reposo: tiene integración con herramientas de seguridad.\n",
    "\n",
    "Tendremos hasta 10 nodos administrando toda la parte de rendimiento y de cache en nuestra db en dynamo.\n",
    "\n",
    "### Caso de Uso 01:\n",
    "\n",
    "![](img_160.png)\n",
    "\n",
    "El caso de uso es necesitar una velocidad muy alta para consumir la data en un tiempo de respuesta muy rápido.\n",
    "\n",
    "Necesitamos almacenar un listado de 60mil usuarios y utilizarlo como una verificación antes de ingestarlo en un endpoint, con lo cual si el usuario ya existia se devolvía la petición y si no está se ingesta.\n",
    "\n",
    "Entonces cuando tengamos app en RealTime pensaremos en DAX.\n",
    "\n",
    "![](img_161.png)\n",
    "\n",
    "Un api gateway es un servicio que va a recibir las solicitud y por detrás va a orquestas o disparar otros servicios basado en operaciones post o get\n",
    "\n",
    "Las operaciones POST y GET se disparan en paralelo\n",
    "\n",
    "### Visto desde la consola de AWS:\n",
    "\n",
    "![](img_162.png)\n",
    "\n",
    "![](img_163.png)\n",
    "\n",
    "![](img_164.png)\n",
    "\n",
    "![](img_165.png)\n",
    "\n",
    "![](img_166.png)\n",
    "\n",
    "Luego \"Lanzar Cluster\"\n",
    "\n",
    "![](img_167.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98de0f",
   "metadata": {},
   "source": [
    "## <a name=\"mark_30\"></a> Conclusiones:\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "### Conclusiones del servicio RDS:\n",
    "\n",
    "- Siempre que desplegamos bases de datos en producción es muy recomendado utilizar los despliegues en diferentes zonas con el servicio Multi AZ.\n",
    "\n",
    "- Tenemos diferentes estrategias para optimizar el performance de nuestra base de datos, por ejemplo, implementar réplicas de lectura, utilizar bases de datos en memoria y dividir la base de datos en otras más pequeñas.\n",
    "\n",
    "- El periodo de retención de los backups de nuestra base de datos son máximo 35 días.\n",
    "\n",
    "- Debemos tener en cuenta los tipos de migración (homogéneas y heterogéneas) cuando vamos a migrar nuestra base de datos.\n",
    "\n",
    "- AuroraDB es la base de datos más robusta y potente para grandes cargas de trabajo de AWS, también es la única con servicio de serverless y autoescalamiento.\n",
    "\n",
    "### Conclusiones del servicio DynamoDB:\n",
    "\n",
    "- Es recomendado evitar las operaciones Scan para no afectar la capacidad aprovisionada, en cambio, las operaciones Query funcionan mucho mejor para el rendimiento de la base de datos.\n",
    "\n",
    "- La función de autoscaling se puede programar con lectura y escritura pero debemos tener en cuenta los costos.\n",
    "\n",
    "- Es clave elegir una llave principal adecuada para no afectar el performance de nuestra base de datos, entre más aleatoria sea este valor, mejor será el rendimiento.\n",
    "\n",
    "- Con DynamoDB Streams podemos crear arquitecturas en tiempo real para diferentes aplicaciones.\n",
    "\n",
    "- Cuando tenemos una tabla muy grande, configurar el particionamiento y los límites del mismo son fundamentales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d6408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel_01",
   "language": "python",
   "name": "data_trans_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
